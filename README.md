# ğŸ’¬ AnÃ¡lisis de Sentimiento con RNN, LSTM y ExploraciÃ³n de Transformer

Este proyecto aplica tÃ©cnicas de procesamiento de lenguaje natural (NLP) y aprendizaje profundo para clasificar sentimientos en tweets. El enfoque principal estÃ¡ en comparar dos arquitecturas clÃ¡sicas: **RNN (Recurrent Neural Network)** y **LSTM (Long Short-Term Memory)** usando el dataset **Sentiment140**.

Adicionalmente, se incluye una implementaciÃ³n educativa de un **Transformer bÃ¡sico** en PyTorch como experimento conceptual, sin fines comparativos directos.

---

## ğŸ“Š Dataset

Se utiliza el dataset [Sentiment140](http://help.sentiment140.com/), que contiene 1.6 millones de tweets etiquetados como positivos o negativos.

El dataset se descarga automÃ¡ticamente dentro del notebook usando `wget`, por lo que **no es necesario subirlo manualmente**.

> âš ï¸ En caso de falla con el enlace, puedes obtenerlo desde [Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140).

---

## ğŸ§  Modelos Desarrollados

### ğŸ” RNN vs LSTM (Keras, TensorFlow)
- Entrenamiento de ambas arquitecturas para clasificaciÃ³n binaria
- VisualizaciÃ³n y anÃ¡lisis de precisiÃ³n, F1-score y pÃ©rdida
- ComparaciÃ³n directa entre modelos para determinar el mÃ¡s efectivo

### ğŸ§ª Transformer (PyTorch) â€” *ExploraciÃ³n Conceptual*
- ImplementaciÃ³n desde cero basada en el paper original de Vaswani et al.
- ExplicaciÃ³n didÃ¡ctica de codificaciÃ³n posicional, atenciÃ³n y estructura encoder
- No se compara directamente con RNN o LSTM en mÃ©tricas

---

## ğŸ“ˆ Resultados: RNN vs LSTM

| Modelo     | PrecisiÃ³n | F1-Score | Tiempo de Entrenamiento | TamaÃ±o del Modelo |
|------------|-----------|----------|--------------------------|-------------------|
| RNN        | 72.9%     | 0.72     | ~12 min                  | 24.8 MB           |
| LSTM       | 77.0%     | 0.77     | ~15 min                  | 27.2 MB           |

> âœ… Se eligiÃ³ **LSTM** como modelo final por su mejor desempeÃ±o general y mayor estabilidad durante el entrenamiento.

---

## âš™ï¸ TecnologÃ­as utilizadas

- Python 3
- TensorFlow / Keras
- PyTorch
- scikit-learn
- NLTK
- pandas, numpy, matplotlib

---

## ğŸ“ Estructura del Proyecto

```

sentiment-analysis-rnn-lstm-transformer/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ rnn_vs_lstm.ipynb             
â”‚   â””â”€â”€ transformer_exploration.ipynb 
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rnn_model.keras
â”‚   â”œâ”€â”€ lstm_model.keras
â”‚   â””â”€â”€ transformer_model.pth                           
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

````

---

## ğŸš€ Â¿CÃ³mo ejecutar los notebooks?

1. Clona el repositorio:
```
   git clone https://github.com/tu_usuario/sentiment-analysis-rnn-lstm-transformer.git
   cd sentiment-analysis-rnn-lstm-transformer
```

2. Instala las dependencias:

```
   pip install -r requirements.txt
```

3. Abre y ejecuta los notebooks desde tu entorno favorito:

   * `notebooks/rnn_vs_lstm.ipynb` para la comparaciÃ³n principal
   * `notebooks/transformer_exploration.ipynb` para la arquitectura Transformer educativa

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

---

## ğŸ‘¤ Autor

Desarrollado por \[Tu Nombre AquÃ­].
Incluye aprendizaje profundo aplicado a NLP, anÃ¡lisis comparativo de modelos secuenciales y una exploraciÃ³n didÃ¡ctica de la arquitectura Transformer.

```

---

### Â¿QuÃ© cambiÃ³ respecto a la versiÃ³n anterior?

âœ… Separamos con claridad:
- QuÃ© modelos se comparan realmente (RNN vs LSTM)
- QuÃ© rol cumple el Transformer (educativo, no competitivo)

âœ… Eliminamos al Transformer de la tabla de resultados comparativos

âœ… Hicimos que la intenciÃ³n del proyecto quede inequÃ­voca para quien lo lea en GitHub

---