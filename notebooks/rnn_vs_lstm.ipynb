{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YSPXFloQLxO"
   },
   "source": [
    "# RNN vs LSTM\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Sentimiento: Comparación entre RNN y LSTM\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este notebook presenta una comparación práctica entre dos arquitecturas clásicas de redes neuronales para procesamiento de lenguaje natural (NLP): **RNN (Recurrent Neural Network)** y **LSTM (Long Short-Term Memory)**.\n",
    "\n",
    "Utilizando el dataset **Sentiment140**, se entrena cada modelo para clasificar tweets como positivos o negativos. Se analizan métricas como **precisión**, **F1-score** y **pérdida de validación**, con el objetivo de determinar cuál arquitectura ofrece mejor rendimiento en esta tarea de clasificación de texto.\n",
    "\n",
    "## Motivación\n",
    "\n",
    "Las redes RNN fueron durante años el estándar para modelar secuencias en NLP, pero presentan problemas al manejar dependencias largas. LSTM surgió como una solución a esas limitaciones, gracias a su capacidad de memoria a largo plazo.\n",
    "\n",
    "Este proyecto busca evidenciar, con una implementación práctica, las diferencias entre ambas arquitecturas en términos de:\n",
    "\n",
    "- Desempeño sobre datos reales\n",
    "- Estabilidad del entrenamiento\n",
    "- Tamaño y complejidad del modelo\n",
    "\n",
    "## Herramientas utilizadas\n",
    "- **Python 3.x**\n",
    "- **TensorFlow / Keras** para definición y entrenamiento de modelos\n",
    "- **scikit-learn** para evaluación\n",
    "- **pandas**, **numpy**, **matplotlib**, **seaborn** para análisis y visualización\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAPa4cCXwwM6"
   },
   "source": [
    "## Carga y Procesamiento\n",
    "\n",
    "\n",
    "Esta fuente de datos original posee 1.6 millones de tweets. En este ejercicio se utiliza sólo un subconjunto de ellos.\n",
    "\n",
    "*(también, se puede usar el archivo CSV desde el disco local con 50k registros)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVjPOqThSztA"
   },
   "source": [
    "### Librerías y Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PuIzEg_sxof"
   },
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import wget, re, io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from spellchecker import SpellChecker\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "#Modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_HwEtfQqRii",
    "outputId": "1ad3f372-67a8-48d8-f16c-10e8117d6b4c"
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "url = \"https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip\"\n",
    "\n",
    "wget.download(url)\n",
    "!unzip -n sentiment140-subset.csv.zip\n",
    "data = pd.read_csv('sentiment140-subset.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P1EzEYexblM"
   },
   "source": [
    "### Lectura del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6uU6gk6wuP6",
    "outputId": "dd1fe879-a369-48ad-8a1b-61b3221e56ab"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqwu9NSvxibj"
   },
   "source": [
    "Para esta evaluación trabajaremos con el dataset `sentiment140-subset.csv`, el cual posee 50.000 datos y 2 columnas:\n",
    "\n",
    "* Text: Vendrían a ser los tweets extraídos y nos vendría a indicar una oración.\n",
    "\n",
    "* polarity: Vendría a ser el sentimiento asociado a la oración.\n",
    "La polaridad es 0 o 1. 0 indica negatividad y 1 indica positividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "m3u5zMA8tZRk",
    "outputId": "ae07efa1-b47d-4737-c37c-626efe76a625"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge9sxZvMm_Er"
   },
   "source": [
    "Verificamos si el dataset muestra correctamente los datos y con el resultado podemos que nos los primeros 5 datos en los que sí contiene \"text\" y \"polarity\" por lo tanto corresponde al dataset y se puede empezar a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcSD9wQ5nX3i",
    "outputId": "5ef99f90-d995-47da-c403-03b4b6d02c0f"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYPO_-nMnxAw"
   },
   "source": [
    "Verificamos que no hayan valores faltantes o nulos en nuestro dataset y por el resultado no hay nulos y además nos informa el tipo de ambos datos con los que estamos trabajando:\n",
    "* Polarity (int64): ya que ésta columna son solo 0's y 1's ya que se indica si es positivo o negativo el mensaje.\n",
    "\n",
    "* text (object): ya que ésta columna solo son mensajes, osea una secuencia de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyMuAobmq4bL",
    "outputId": "dce52f67-1a95-4eca-833c-5443337b57ca"
   },
   "outputs": [],
   "source": [
    "print(data['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvPuqGgkx0fY"
   },
   "source": [
    "### Procesamiento del Dataset `sentiment140-subset.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G45CjGo_opjS"
   },
   "source": [
    "Para nuestro modelo RNN necesitaremos limpiar y procesar nuestro dataset para que lo pueda leer en el idioma en el que lee la máquina, osea números(tokenizer) y además eliminar letras redundantes (mayúsculas) y espaciados o saltos de espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4jx9fucyCRO"
   },
   "source": [
    "#### Limpieza de Mayus y espacios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69T9UhK7yGbU",
    "outputId": "8e385496-eb9c-4e00-b7ea-eae24eebae88"
   },
   "outputs": [],
   "source": [
    "def limpiar_texto_mejorado(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'http\\S+|www\\S+', '<URL>', texto)  # reemplazar URLs\n",
    "    texto = re.sub(r'@\\w+', '@user', texto)             # reemplazar menciones\n",
    "    texto = re.sub(r'\\n|\\r|\\t', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    # Mantener apóstrofes para contracciones\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s']\", '', texto)\n",
    "    return texto.strip()\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG57-ETex_fR"
   },
   "source": [
    "Dado que el texto sin procesar es difícil de procesar por una red neuronal, tenemos que convertirlo en su representación numérica correspondiente.\n",
    "\n",
    "Para ello, inicializamos su tokenizador estableciendo la cantidad máxima de palabras (características/tokens) que desea convertir en tokens en una oración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWCpHdHUyK7-"
   },
   "source": [
    "#### Tokenizer y Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHNJpOlIsmMy"
   },
   "outputs": [],
   "source": [
    "max_features = 25000\n",
    "maxlen = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7hzF-GJsovR"
   },
   "source": [
    "Elegiremos un máximo de 4000 caracteres para nuestro tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lMWMorztj4L"
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento robusto\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_features,\n",
    "    oov_token=\"<OOV>\",\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen)\n",
    "y = data['polarity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-9BXKNnykOi"
   },
   "source": [
    "\n",
    "Rellenamos las secuencias tokenizadas para mantener la misma longitud en todas las secuencias de entrada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pz2FWeGNtr8d",
    "outputId": "05a392e7-e0ef-4e9c-f3e0-cdcd5b5df2cc"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqcTnB-Zyqm3"
   },
   "source": [
    "Por último, imprimimos la forma del vector de entrada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGVUbDb_yxPU"
   },
   "source": [
    "De este modo, creamos 50 000 vectores de entrada, cada uno de longitud 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3APJbH2LtO_u",
    "outputId": "a9e8074c-a0d8-4fb2-b18a-cd7069894a04"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXv4CurJx6W_"
   },
   "source": [
    "## Modelo RNN - LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMLqdfcsPCV2"
   },
   "outputs": [],
   "source": [
    "# Hiperparámetros optimizados\n",
    "embed_dim = 256\n",
    "lstm_units = 192\n",
    "dense_units = 96\n",
    "dropout_rate = 0.35\n",
    "l1l2 = (0.0001, 0.0001)\n",
    "batch_size = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7cs_8g-dVWW"
   },
   "outputs": [],
   "source": [
    "# Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKANlIomhIz9",
    "outputId": "a16c393e-48a9-4de7-fc74-af5d78f87e81"
   },
   "outputs": [],
   "source": [
    "# Calcular class weights\n",
    "class_counts = np.bincount(y_train)\n",
    "total = len(y_train)\n",
    "weight_for_0 = (1 / class_counts[0]) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_counts[1]) * (total / 2.0)\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(f\"Class weights: 0={weight_for_0:.4f}, 1={weight_for_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fo9H__UWi8Ka"
   },
   "outputs": [],
   "source": [
    "# Capa de atención personalizada\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                initializer=\"glorot_uniform\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                initializer=\"zeros\")\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        et = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        at = tf.keras.backend.softmax(et, axis=1)\n",
    "        at = tf.keras.backend.permute_dimensions(at, (0, 2, 1))\n",
    "        output = tf.keras.backend.batch_dot(at, x)\n",
    "        return tf.keras.backend.squeeze(output, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc-sIz_ePFwu",
    "outputId": "0319d5c1-bd1e-462d-c4de-2491cc913508"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "        embeddings_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "        input_length=maxlen\n",
    "    ),\n",
    "    tf.keras.layers.SpatialDropout1D(dropout_rate),\n",
    "\n",
    "    # Capa Bidireccional LSTM (con return_sequences para atención)\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(\n",
    "            lstm_units,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=dropout_rate * 0.7,\n",
    "            kernel_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "            recurrent_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "            return_sequences=True  # Necesario para atención\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Capa de atención personalizada\n",
    "    AttentionLayer(),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(\n",
    "        dense_units,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l1_l2(*l1l2)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgXS8q8FPGKj"
   },
   "outputs": [],
   "source": [
    "# Optimizador con learning rate programado\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00015,  # LR inicial más alto\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "LlTJ647nPJZp",
    "outputId": "4f0e037c-b6cf-43a0-9650-d0311ad0450e"
   },
   "outputs": [],
   "source": [
    "# Callbacks mejorados\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=4,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.weights.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        min_delta=0.005\n",
    "    )\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uQefOZPT-8-",
    "outputId": "ccc5f87c-719d-4027-8b42-aca2dca69f49"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8px0LwqwohF"
   },
   "outputs": [],
   "source": [
    "# Paso 1: Construir el modelo\n",
    "model.build(input_shape=(None, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUl8jeULng41",
    "outputId": "d676da71-daab-4a44-ab9c-f2c8ea735275"
   },
   "outputs": [],
   "source": [
    "# Cargar modelo (de requerirlo)\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bX2sGj5uhnR",
    "outputId": "a0c2b54c-b6ed-4097-9e35-f03a841bfc38"
   },
   "outputs": [],
   "source": [
    "# Predecir\n",
    "y_pred_output = model.predict(X_test)\n",
    "y_pred_probs = y_pred_output.flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or8HagQswxUO",
    "outputId": "aea0992f-e832-423e-cd44-ef3943b2132d"
   },
   "outputs": [],
   "source": [
    "# Métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\" Métricas\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTtwuQkNxNYZ",
    "outputId": "1a324d77-73c5-4959-9eaa-d85bae6332f4"
   },
   "outputs": [],
   "source": [
    "# Reporte de clasificación\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Q62rAsWwtzQz",
    "outputId": "77d24e2a-dc7c-4a9f-8978-c60ce458ef27"
   },
   "outputs": [],
   "source": [
    "# Visualización\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy de Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy de Validación')\n",
    "plt.title('Accuracy del Modelo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Época')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "-8loMBpEv8qk",
    "outputId": "961d8db2-e694-4a7e-9274-339645aa8cdb"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 3)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.ylabel('Realidad')\n",
    "plt.xlabel('Predicción')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "maKA4C0CMKZC",
    "outputId": "9c43aa96-0a30-4e93-ec56-e12eb3c1d7e4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Modelo\": [\"Final (v3)\", \"Versión 1\", \"Versión 2\"],\n",
    "    \"val_accuracy_peak\": [0.7805, 0.7779, 0.7790],\n",
    "    \"val_loss_min\": [0.5704, 0.5717, 0.5436],\n",
    "    \"precision_peak\": [0.7848, 0.7806, 0.7870],\n",
    "    \"recall_peak\": [0.7829, 0.7904, 0.7671]\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# val_accuracy\n",
    "axes[0, 0].bar(df[\"Modelo\"], df[\"val_accuracy_peak\"], color=\"skyblue\")\n",
    "axes[0, 0].set_title(\"Val Accuracy Pico\")\n",
    "axes[0, 0].set_ylim(0.75, 0.79)\n",
    "axes[0, 0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "#  val_loss\n",
    "axes[0, 1].bar(df[\"Modelo\"], df[\"val_loss_min\"], color=\"salmon\")\n",
    "axes[0, 1].set_title(\"Val Loss Mínimo\")\n",
    "axes[0, 1].invert_yaxis()  # Menor es mejor\n",
    "axes[0, 1].set_ylabel(\"Loss\")\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].bar(df[\"Modelo\"], df[\"precision_peak\"], color=\"mediumseagreen\")\n",
    "axes[1, 0].set_title(\"Precisión Pico\")\n",
    "axes[1, 0].set_ylabel(\"Precision\")\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].bar(df[\"Modelo\"], df[\"recall_peak\"], color=\"orange\")\n",
    "axes[1, 1].set_title(\"Recall Pico\")\n",
    "axes[1, 1].set_ylabel(\"Recall\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlabel(\"Modelo\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwW-zQbvJC5W"
   },
   "source": [
    "### Justificación del Modelo Final Seleccionado\n",
    "\n",
    "Se probaron tres configuraciones diferentes del modelo LSTM. A continuación, se presenta una comparación de sus principales características y métricas de rendimiento:\n",
    "\n",
    "- **Versión 1** mostró un buen balance entre precisión y recall, pero el entrenamiento se detuvo temprano debido a estancamiento en val_accuracy. Además, su embed_dim era menor (192), lo cual puede limitar la capacidad de representación semántica del texto.\n",
    "\n",
    "- **Versión 2** tuvo el mejor val_loss (0.5436), pero su val_accuracy fue levemente inferior y mostró cierta sobrecarga computacional (hasta 50 épocas). Su recall también bajó con respecto a la Versión 1, lo cual podría perjudicar la detección de casos positivos.\n",
    "\n",
    "- **Versión final (v3)** logra un excelente balance:  \n",
    "   - Tiene **mejor precisión-recall equilibrado** (ambos ~0.78).\n",
    "   - La val_accuracy fue la **más alta** (0.7805).\n",
    "   - Uso razonable de recursos (solo 30 épocas).\n",
    "   - Su tamaño de embedding y número de unidades LSTM es robusto pero no excesivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i84R0n16cudS"
   },
   "source": [
    "### Justificación del Modelo Final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_Yn8aNDcwK7"
   },
   "source": [
    "El modelo seleccionado fue la **versión 3**, con una configuración optimizada de hiperparámetros. Las decisiones se justifican de la siguiente manera:\n",
    "\n",
    "- **Épocas (30) + EarlyStopping:** El entrenamiento se detuvo automáticamente en la época 29, cuando la mejora en validación se estabilizó. Las curvas de pérdida muestran convergencia clara sin overfitting. Esto indica una elección adecuada de `epochs` y `patience`.\n",
    "\n",
    "- **Tasa de aprendizaje inicial: 1.5e-4** → Se utilizó con `ReduceLROnPlateau`, lo cual permitió un **ajuste dinámico** de la LR. Esto ayudó a mantener mejoras en precisión y recall incluso en etapas tardías del entrenamiento, estabilizando las métricas.\n",
    "\n",
    "- **Batch size: 256** → Este tamaño balanceó eficiencia computacional y estabilidad del gradiente. En pruebas con batch sizes más bajos (128), se observó mayor oscilación en la curva de pérdida y menor precisión.\n",
    "\n",
    "En comparación con versiones anteriores, esta configuración alcanzó:\n",
    "- **Mayor accuracy de validación (78.05%)**\n",
    "- **Mejor precisión y F1-score**\n",
    "- **Menor pérdida en validación**\n",
    "\n",
    "#### Posibles mejoras:\n",
    "- Ajustar la LR inicial a 1e-4 podría permitir convergencia más estable aún.\n",
    "- Probar capas adicionales (p.ej., GRU + LSTM híbrido) podría mejorar el F1 en casos ambiguos.\n",
    "\n",
    "Estas decisiones fueron fundamentadas en pruebas empíricas y evidencia gráfica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUGIPtH2WJ-L"
   },
   "source": [
    "### Análisis de Hiperparámetros y su Impacto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGEZZYt6WMT7"
   },
   "source": [
    "| Hiperparámetro | Variación entre versiones | Impacto observado |\n",
    "|----------------|---------------------------|--------------------|\n",
    "| `embed_dim`    | 192 -> 256                 | Mejor representación semántica; el modelo final tuvo mayor precision y recall. |\n",
    "| `lstm_units`   | 192 -> 256 (v2)            | Aumentó capacidad, pero incrementó el tiempo de entrenamiento sin gran mejora en accuracy. |\n",
    "| `dropout_rate` | 0.4 -> 0.3 / 0.35          | Tasas moderadas mejoraron la generalización; tasas altas redujeron recall. |\n",
    "| `learning_rate`| 1e-4 / 1.5e-4 / 3e-5       | 1.5e-4 ofreció convergencia estable y buen rendimiento sin estancarse. |\n",
    "| `epochs`       | 30 -> 50                   | A partir de época 20 no hubo grandes mejoras; el modelo final usó early stopping. |\n",
    "| `batch_size`   | 256 (constante)           | Balance entre velocidad de entrenamiento y estabilidad del gradiente. |\n",
    "\n",
    "Las variaciones anteriores permitieron identificar que un embedding y LSTM intermedios (256, 192) combinados con una tasa de aprendizaje moderada (1.5e-4) ofrecen el mejor rendimiento sin sobreentrenar ni sobrecargar el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngUzYbEOcecD"
   },
   "source": [
    "### Análisis del desempeño del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6JzA9TNchN8"
   },
   "source": [
    "El modelo final logró una **accuracy del 77.0%** y un **F1-score de 0.7697**, valores consistentes con una buena capacidad de generalización en datos no vistos. La precisión (0.7698) y el recall (0.7695) están balanceados, lo que indica que el modelo no favorece excesivamente ninguna clase.\n",
    "\n",
    "Estos resultados están directamente relacionados con los **ajustes de hiperparámetros**, entre ellos:\n",
    "\n",
    "- **Dropout del 35%** y regularización L1/L2 ayudaron a reducir el overfitting, estabilizando las curvas de pérdida y mejorando la precisión de validación tras la 10.ª época.\n",
    "- El uso de **Bidirectional LSTM** permitió capturar contextos antes y después de cada palabra, mejorando recall y precisión frente a versiones unidireccionales.\n",
    "- La **capa de atención** ayudó a enfocar el modelo en tokens relevantes para el sentimiento, lo que se refleja en un mejor F1-score en comparación con versiones sin atención (~+1.5 pp).\n",
    "- El **batch size de 256** permitió convergencia más estable en pocas épocas, sin saltos erráticos.\n",
    "\n",
    "En conclusión, las métricas obtenidas están directamente influenciadas por decisiones específicas del modelo y evidencian una mejora sustancial respecto a versiones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnDt_h2Jr-qz"
   },
   "source": [
    "## Modelo RNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "wJo_rAw5sCMK",
    "outputId": "c0c83286-ed3c-4618-e7ae-225f77352a0c"
   },
   "outputs": [],
   "source": [
    "# Modelo RNN simple\n",
    "model_rnn_simple = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "        input_length=maxlen\n",
    "    ),\n",
    "    tf.keras.layers.SpatialDropout1D(dropout_rate),\n",
    "\n",
    "    # Capa RNN simple\n",
    "    tf.keras.layers.SimpleRNN(\n",
    "        lstm_units, # Reutilizamos el tamaño de unidades para comparación justa\n",
    "        dropout=dropout_rate,\n",
    "        recurrent_dropout=dropout_rate * 0.7,\n",
    "        return_sequences=False # Para una clasificación simple final\n",
    "    ),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(\n",
    "        dense_units,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn_simple.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', # Optimizador simple para empezar\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_rnn_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzOHhz8kuQEJ"
   },
   "source": [
    "\n",
    "Entrenamiento (usando menos epochs y batch size más pequeño para RNN simple)\n",
    "Se usan menos epochs y batch size más pequeño porque RNN simple suele ser más rápido de entrenar\n",
    "pero puede tener problemas con secuencias largas y gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_UU8q6dxsH8P",
    "outputId": "ba3c869c-67d7-4168-aa21-1890df4ec53e"
   },
   "outputs": [],
   "source": [
    "history_rnn_simple = model_rnn_simple.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15, # Menos epochs para RNN simple\n",
    "    batch_size=128, # Batch size más pequeño\n",
    "    validation_split=0.2,\n",
    "    # No usamos callbacks avanzados ni class_weights para mantenerlo \"simple\"\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluación\n",
    "loss_rnn_simple, accuracy_rnn_simple, precision_rnn_simple, recall_rnn_simple = model_rnn_simple.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\" Métricas RNN Simple\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Accuracy:  {accuracy_rnn_simple:.4f}\")\n",
    "print(f\"Precision: {precision_rnn_simple:.4f}\")\n",
    "print(f\"Recall:    {recall_rnn_simple:.4f}\")\n",
    "# Calculate F1 for RNN simple\n",
    "f1_rnn_simple = 2 * (precision_rnn_simple * recall_rnn_simple) / (precision_rnn_simple + recall_rnn_simple + 1e-7) # Add epsilon for stability\n",
    "print(f\"F1-score:  {f1_rnn_simple:.4f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Predecir para classification report and confusion matrix\n",
    "y_pred_rnn_simple_probs = model_rnn_simple.predict(X_test).flatten()\n",
    "y_pred_rnn_simple = (y_pred_rnn_simple_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Reporte de clasificación RNN Simple\n",
    "print(\"\\nClassification Report (RNN Simple):\")\n",
    "print(classification_report(y_test, y_pred_rnn_simple, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Visualización para RNN Simple\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Pérdida RNN Simple\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_rnn_simple.history['loss'], label='Train Loss (RNN Simple)')\n",
    "plt.plot(history_rnn_simple.history['val_loss'], label='Validation Loss (RNN Simple)')\n",
    "plt.title('Model Loss (RNN Simple)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Matriz de confusión RNN Simple\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_rnn_simple = confusion_matrix(y_test, y_pred_rnn_simple)\n",
    "sns.heatmap(cm_rnn_simple, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.title('Confusion Matrix (RNN Simple)')\n",
    "plt.ylabel('Realidad')\n",
    "plt.xlabel('Predicción')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo (de requerirlo)\n",
    "from keras.models import load_model\n",
    "\n",
    "model_rnn_simple = load_model(\"rnn_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oveb1NoSu_nI"
   },
   "source": [
    "## Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "6aK_Q6hGxhIl",
    "outputId": "ae3aa50d-41cc-41cf-b3f6-2d47a8ff401a"
   },
   "outputs": [],
   "source": [
    "# Gráfico de métricas finales (Barras)\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "lstm_scores = [accuracy_best, precision_best, recall_best, f1_best]\n",
    "rnn_scores = [accuracy_rnn_simple, precision_rnn_simple, recall_rnn_simple, f1_rnn_simple]\n",
    "\n",
    "x = np.arange(len(metrics_names))  # posiciones en el eje x\n",
    "width = 0.35  # ancho de las barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, lstm_scores, width, label='Best Model (LSTM)', color='steelblue')\n",
    "rects2 = ax.bar(x + width/2, rnn_scores, width, label='RNN Simple', color='orange')\n",
    "\n",
    "# Etiquetas y formato\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparación de Métricas Finales por Modelo')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_names)\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar valores en las barras\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.4f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # Desplazamiento vertical\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\"*65)\n",
    "print(\" \"*15 + \"COMPARACIÓN DE MÉTRICAS DE MODELOS \")\n",
    "print(\"-\"*65)\n",
    "print(comparison_df)\n",
    "print(\"-\"*65 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoSlPoiNIiTB"
   },
   "source": [
    "### Análisis Comparativo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLyQ0Wo6QF8N"
   },
   "source": [
    "Con el resulado de ambos modelos podemos comparar sus metricas de clasificación y así poder diferenciarlos para detectar cuál tiene un mejor rendimiento para realizar predicción de sentimientos.\n",
    "\n",
    "\n",
    "| Métrica   | LSTM   | RNN Simple | Diferencia |\n",
    "| --------- | ------ | ---------- | ---------- |\n",
    "| Accuracy  | 0.7704 | 0.7292     | +0.0412    |\n",
    "| Precision | 0.7698 | 0.7274     | +0.0424    |\n",
    "| Recall    | 0.7695 | 0.7306     | +0.0389    |\n",
    "| F1-score  | 0.7697 | 0.7290     | +0.0407    |\n",
    "\n",
    "**Ventajas del modelo LSTM**\n",
    "\n",
    "Mayor rendimiento en todas las métricas clave:\n",
    "\n",
    "* Accuracy: El LSTM supera al RNN simple por un margen de `+4.12%`, lo que indica que clasifica correctamente más muestras en general.\n",
    "\n",
    "* Precision y Recall: El LSTM es más preciso (menos falsos positivos) y tiene mejor sensibilidad (menos falsos negativos), lo que significa que detecta mejor las clases positivas sin sobreclasificarlas.\n",
    "\n",
    "* F1-score: La puntuación F1 es `+4.07%` superior en LSTM, lo que sugiere un balance más efectivo entre ambas.\n",
    "\n",
    "Mayor capacidad de aprendizaje secuencial:\n",
    "\n",
    "El modelo LSTM incorpora puertas (como input, forget y output gates) que le permiten capturar dependencias a largo plazo en los datos, algo que el RNN simple no logra con la misma eficacia.\n",
    "\n",
    "Mayor estabilidad y generalización:\n",
    "\n",
    "El modelo LSTM, al ser más robusto frente al desvanecimiento del gradiente, aprende de manera más estable durante el entrenamiento y generaliza mejor al conjunto de prueba.\n",
    "\n",
    "**Limitaciones del modelo RNN Simple**\n",
    "\n",
    "Aunque el RNN simple es más liviano computacionalmente, su rendimiento es notablemente inferior en todos los aspectos y se ve claramente comparando ambos modelos en el gráfico. Éste modelo es más propenso al desvanecimiento del gradiente, lo que limita su capacidad para aprender dependencias temporales largas.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "El modelo final elegido es una arquitectura LSTM bidireccional con atención, que logra un equilibrio ideal entre rendimiento, estabilidad y capacidad de modelar lenguaje secuencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh-ljJl7QIRh"
   },
   "source": [
    "## Justificación del Modelo Final: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cHAp3UnSRLz"
   },
   "source": [
    "Se eligió el modelo LSTM (Long Short-Term Memory) como modelo final debido a su mejor rendimiento cuantitativo y cualitativo en comparación con la arquitectura RNN simple, y por su capacidad superior para aprender patrones secuenciales en los datos.\n",
    "\n",
    "En nuestro caso:\n",
    "\n",
    "- Trabajamos con tweets donde la clave del sentimiento puede aparecer en cualquier parte de la frase (dependencias de largo alcance).  \n",
    "- En la comparación empírica, el modelo LSTM superó sistemáticamente a la RNN simple en accuracy, precision, recall y F1-score (≈ +4 pp en cada métrica).  \n",
    "- Si bien la RNN simple es más ligera (menos parámetros y entrenamiento algo más rápido), su menor estabilidad y peor desempeño la hacen menos adecuada para esta tarea de análisis de sentimientos.\n",
    "\n",
    "Por estas razones, se eligió **LSTM bidireccional con atención**, que combina la robustez de las LSTM con la capacidad de enfocarse en las palabras más relevantes mediante la capa de atención.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djl__QEQSW9D"
   },
   "source": [
    "## Prediccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoK57e0wSWcG"
   },
   "outputs": [],
   "source": [
    "def predecir_sentimiento(texto):\n",
    "    if 'model' not in globals() or 'tokenizer' not in globals():\n",
    "        print(\"Error: El modelo o el tokenizer no están definidos. Asegúrate de haber entrenado el modelo previamente.\")\n",
    "        return None\n",
    "\n",
    "    # Limpiar y tokenizar el texto de entrada\n",
    "    texto_limpio = limpiar_texto_mejorado(texto)\n",
    "    secuencia = tokenizer.texts_to_sequences([texto_limpio])\n",
    "    secuencia_padding = tf.keras.preprocessing.sequence.pad_sequences(secuencia, maxlen=maxlen)\n",
    "\n",
    "    # Realizar la predicción\n",
    "    prediccion_prob = model.predict(secuencia_padding)[0][0]\n",
    "\n",
    "    # Interpretar la predicción\n",
    "    if prediccion_prob > 0.5:\n",
    "        return 'Positivo'\n",
    "    else:\n",
    "        return 'Negativo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeQ9rbqRaqI3",
    "outputId": "a0030079-6ce3-4c22-972c-550cd49457b9"
   },
   "outputs": [],
   "source": [
    "frases_positivas = [\n",
    "    \"I absolutely loved this!\",                      # Muy obvio\n",
    "    \"This is fantastic and made my day.\",            # Claro y entusiasta\n",
    "    \"I'm really happy with how it turned out.\",      # Positivo explícito\n",
    "    \"Not bad at all, pretty good actually.\",         # Sutil, con negación\n",
    "    \"It was better than I expected.\"                 # Positivo implícito\n",
    "]\n",
    "\n",
    "frases_negativas = [\n",
    "    \"This is the worst thing ever.\",                 # Muy obvio\n",
    "    \"I completely hated it.\",                        # Claro y negativo\n",
    "    \"I'm really disappointed with this.\",            # Negativo explícito\n",
    "    \"Not what I hoped for, honestly.\",               # Sutil, con decepción\n",
    "    \"It wasn't great.\"                               # Negativo implícito\n",
    "]\n",
    "\n",
    "print(\"🟢 Frases Positivas:\")\n",
    "for frase in frases_positivas:\n",
    "    sentimiento = predecir_sentimiento(frase)\n",
    "    print(f\"Texto: '{frase}' -> Sentimiento: {sentimiento}\")\n",
    "\n",
    "print(\"\\n🔴 Frases Negativas:\")\n",
    "for frase in frases_negativas:\n",
    "    sentimiento = predecir_sentimiento(frase)\n",
    "    print(f\"Texto: '{frase}' -> Sentimiento: {sentimiento}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ4OuYifa5D3"
   },
   "source": [
    "### Validación Manual de Casos Reales\n",
    "\n",
    "Se probó el modelo con frases en inglés que representan distintos niveles de carga emocional y estructuras lingüísticas:\n",
    "\n",
    "| Texto                                     | Esperado | Predicho | Correcto |\n",
    "|------------------------------------------|----------|----------|----------|\n",
    "| I absolutely loved this!                 | Positivo | Positivo | ✅       |\n",
    "| Not bad at all, pretty good actually.    | Positivo | Negativo | ❌       |\n",
    "| I completely hated it.                   | Negativo | Positivo | ❌       |\n",
    "| It wasn't great.                         | Negativo | Positivo | ❌       |\n",
    "\n",
    "Aunque el modelo muestra buen rendimiento en ejemplos directos, falló en frases con negaciones y expresiones suaves. Esto evidencia una limitación de los modelos LSTM puros para interpretar matices y estructuras complejas del lenguaje natural.\n",
    "\n",
    "Estos resultados muestran que el modelo funciona bien en lo general, pero no:\n",
    "\n",
    "* Comprende bien negaciones compuestas (\"not bad\", \"wasn't great\").\n",
    "* Interpreta correctamente palabras negativas cuando están fuera del patrón de entrenamiento.\n",
    "* Modela bien el contexto y la inversión semántica (ej. ironía o sarcasmo leve).\n",
    "\n",
    "Este tipo de errores son típicos en LSTM puros sin embeddings semánticos preentrenados (como los de BERT o GPT), porque dependen mucho de patrones superficiales y del vocabulario aprendido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGXGJhWeaXvp"
   },
   "source": [
    "### Consideraciones sobre el Idioma del Dataset\n",
    "\n",
    "El modelo fue entrenado exclusivamente con el dataset **Sentiment140**, el cual está compuesto por tweets en **inglés**. Por esta razón, su vocabulario, embeddings y patrones de sentimiento fueron aprendidos únicamente a partir de ese idioma.\n",
    "\n",
    "Durante pruebas preliminares, se observó que frases en español eran clasificadas incorrectamente. Al cambiar los ejemplos de prueba al inglés, el modelo respondió correctamente, clasificando de forma precisa tanto frases positivas como negativas.\n",
    "\n",
    "Este modelo no está diseñado para tareas de análisis de sentimientos en español. Para ello, se requeriría un corpus en español o un modelo multilingüe (como `BERT multilingual`).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4P1EzEYexblM",
    "rnDt_h2Jr-qz",
    "oveb1NoSu_nI"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
