{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YSPXFloQLxO"
   },
   "source": [
    "# RNN vs LSTM\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Sentimiento: Comparaci√≥n entre RNN y LSTM\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este notebook presenta una comparaci√≥n pr√°ctica entre dos arquitecturas cl√°sicas de redes neuronales para procesamiento de lenguaje natural (NLP): **RNN (Recurrent Neural Network)** y **LSTM (Long Short-Term Memory)**.\n",
    "\n",
    "Utilizando el dataset **Sentiment140**, se entrena cada modelo para clasificar tweets como positivos o negativos. Se analizan m√©tricas como **precisi√≥n**, **F1-score** y **p√©rdida de validaci√≥n**, con el objetivo de determinar cu√°l arquitectura ofrece mejor rendimiento en esta tarea de clasificaci√≥n de texto.\n",
    "\n",
    "## Motivaci√≥n\n",
    "\n",
    "Las redes RNN fueron durante a√±os el est√°ndar para modelar secuencias en NLP, pero presentan problemas al manejar dependencias largas. LSTM surgi√≥ como una soluci√≥n a esas limitaciones, gracias a su capacidad de memoria a largo plazo.\n",
    "\n",
    "Este proyecto busca evidenciar, con una implementaci√≥n pr√°ctica, las diferencias entre ambas arquitecturas en t√©rminos de:\n",
    "\n",
    "- Desempe√±o sobre datos reales\n",
    "- Estabilidad del entrenamiento\n",
    "- Tama√±o y complejidad del modelo\n",
    "\n",
    "## Herramientas utilizadas\n",
    "- **Python 3.x**\n",
    "- **TensorFlow / Keras** para definici√≥n y entrenamiento de modelos\n",
    "- **scikit-learn** para evaluaci√≥n\n",
    "- **pandas**, **numpy**, **matplotlib**, **seaborn** para an√°lisis y visualizaci√≥n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAPa4cCXwwM6"
   },
   "source": [
    "## Carga y Procesamiento\n",
    "\n",
    "\n",
    "Esta fuente de datos original posee 1.6 millones de tweets. En este ejercicio se utiliza s√≥lo un subconjunto de ellos.\n",
    "\n",
    "*(tambi√©n, se puede usar el archivo CSV desde el disco local con 50k registros)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVjPOqThSztA"
   },
   "source": [
    "### Librer√≠as y Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PuIzEg_sxof"
   },
   "outputs": [],
   "source": [
    "#Librer√≠as\n",
    "import pandas as pd\n",
    "import wget, re, io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from spellchecker import SpellChecker\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "#Modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_HwEtfQqRii",
    "outputId": "1ad3f372-67a8-48d8-f16c-10e8117d6b4c"
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "url = \"https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip\"\n",
    "\n",
    "wget.download(url)\n",
    "!unzip -n sentiment140-subset.csv.zip\n",
    "data = pd.read_csv('sentiment140-subset.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P1EzEYexblM"
   },
   "source": [
    "### Lectura del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6uU6gk6wuP6",
    "outputId": "dd1fe879-a369-48ad-8a1b-61b3221e56ab"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqwu9NSvxibj"
   },
   "source": [
    "Para esta evaluaci√≥n trabajaremos con el dataset `sentiment140-subset.csv`, el cual posee 50.000 datos y 2 columnas:\n",
    "\n",
    "* Text: Vendr√≠an a ser los tweets extra√≠dos y nos vendr√≠a a indicar una oraci√≥n.\n",
    "\n",
    "* polarity: Vendr√≠a a ser el sentimiento asociado a la oraci√≥n.\n",
    "La polaridad es 0 o 1. 0 indica negatividad y 1 indica positividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "m3u5zMA8tZRk",
    "outputId": "ae07efa1-b47d-4737-c37c-626efe76a625"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge9sxZvMm_Er"
   },
   "source": [
    "Verificamos si el dataset muestra correctamente los datos y con el resultado podemos que nos los primeros 5 datos en los que s√≠ contiene \"text\" y \"polarity\" por lo tanto corresponde al dataset y se puede empezar a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcSD9wQ5nX3i",
    "outputId": "5ef99f90-d995-47da-c403-03b4b6d02c0f"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYPO_-nMnxAw"
   },
   "source": [
    "Verificamos que no hayan valores faltantes o nulos en nuestro dataset y por el resultado no hay nulos y adem√°s nos informa el tipo de ambos datos con los que estamos trabajando:\n",
    "* Polarity (int64): ya que √©sta columna son solo 0's y 1's ya que se indica si es positivo o negativo el mensaje.\n",
    "\n",
    "* text (object): ya que √©sta columna solo son mensajes, osea una secuencia de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyMuAobmq4bL",
    "outputId": "dce52f67-1a95-4eca-833c-5443337b57ca"
   },
   "outputs": [],
   "source": [
    "print(data['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvPuqGgkx0fY"
   },
   "source": [
    "### Procesamiento del Dataset `sentiment140-subset.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G45CjGo_opjS"
   },
   "source": [
    "Para nuestro modelo RNN necesitaremos limpiar y procesar nuestro dataset para que lo pueda leer en el idioma en el que lee la m√°quina, osea n√∫meros(tokenizer) y adem√°s eliminar letras redundantes (may√∫sculas) y espaciados o saltos de espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4jx9fucyCRO"
   },
   "source": [
    "#### Limpieza de Mayus y espacios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69T9UhK7yGbU",
    "outputId": "8e385496-eb9c-4e00-b7ea-eae24eebae88"
   },
   "outputs": [],
   "source": [
    "def limpiar_texto_mejorado(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'http\\S+|www\\S+', '<URL>', texto)  # reemplazar URLs\n",
    "    texto = re.sub(r'@\\w+', '@user', texto)             # reemplazar menciones\n",
    "    texto = re.sub(r'\\n|\\r|\\t', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    # Mantener ap√≥strofes para contracciones\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s']\", '', texto)\n",
    "    return texto.strip()\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG57-ETex_fR"
   },
   "source": [
    "Dado que el texto sin procesar es dif√≠cil de procesar por una red neuronal, tenemos que convertirlo en su representaci√≥n num√©rica correspondiente.\n",
    "\n",
    "Para ello, inicializamos su tokenizador estableciendo la cantidad m√°xima de palabras (caracter√≠sticas/tokens) que desea convertir en tokens en una oraci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWCpHdHUyK7-"
   },
   "source": [
    "#### Tokenizer y Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHNJpOlIsmMy"
   },
   "outputs": [],
   "source": [
    "max_features = 25000\n",
    "maxlen = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7hzF-GJsovR"
   },
   "source": [
    "Elegiremos un m√°ximo de 4000 caracteres para nuestro tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lMWMorztj4L"
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento robusto\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=max_features,\n",
    "    oov_token=\"<OOV>\",\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen)\n",
    "y = data['polarity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-9BXKNnykOi"
   },
   "source": [
    "\n",
    "Rellenamos las secuencias tokenizadas para mantener la misma longitud en todas las secuencias de entrada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pz2FWeGNtr8d",
    "outputId": "05a392e7-e0ef-4e9c-f3e0-cdcd5b5df2cc"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqcTnB-Zyqm3"
   },
   "source": [
    "Por √∫ltimo, imprimimos la forma del vector de entrada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGVUbDb_yxPU"
   },
   "source": [
    "De este modo, creamos 50 000 vectores de entrada, cada uno de longitud 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3APJbH2LtO_u",
    "outputId": "a9e8074c-a0d8-4fb2-b18a-cd7069894a04"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXv4CurJx6W_"
   },
   "source": [
    "## Modelo RNN - LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMLqdfcsPCV2"
   },
   "outputs": [],
   "source": [
    "# Hiperpar√°metros optimizados\n",
    "embed_dim = 256\n",
    "lstm_units = 192\n",
    "dense_units = 96\n",
    "dropout_rate = 0.35\n",
    "l1l2 = (0.0001, 0.0001)\n",
    "batch_size = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7cs_8g-dVWW"
   },
   "outputs": [],
   "source": [
    "# Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKANlIomhIz9",
    "outputId": "a16c393e-48a9-4de7-fc74-af5d78f87e81"
   },
   "outputs": [],
   "source": [
    "# Calcular class weights\n",
    "class_counts = np.bincount(y_train)\n",
    "total = len(y_train)\n",
    "weight_for_0 = (1 / class_counts[0]) * (total / 2.0)\n",
    "weight_for_1 = (1 / class_counts[1]) * (total / 2.0)\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(f\"Class weights: 0={weight_for_0:.4f}, 1={weight_for_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fo9H__UWi8Ka"
   },
   "outputs": [],
   "source": [
    "# Capa de atenci√≥n personalizada\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                initializer=\"glorot_uniform\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                initializer=\"zeros\")\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        et = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        at = tf.keras.backend.softmax(et, axis=1)\n",
    "        at = tf.keras.backend.permute_dimensions(at, (0, 2, 1))\n",
    "        output = tf.keras.backend.batch_dot(at, x)\n",
    "        return tf.keras.backend.squeeze(output, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc-sIz_ePFwu",
    "outputId": "0319d5c1-bd1e-462d-c4de-2491cc913508"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "        embeddings_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "        input_length=maxlen\n",
    "    ),\n",
    "    tf.keras.layers.SpatialDropout1D(dropout_rate),\n",
    "\n",
    "    # Capa Bidireccional LSTM (con return_sequences para atenci√≥n)\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(\n",
    "            lstm_units,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=dropout_rate * 0.7,\n",
    "            kernel_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "            recurrent_regularizer=tf.keras.regularizers.l1_l2(*l1l2),\n",
    "            return_sequences=True  # Necesario para atenci√≥n\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Capa de atenci√≥n personalizada\n",
    "    AttentionLayer(),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(\n",
    "        dense_units,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l1_l2(*l1l2)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgXS8q8FPGKj"
   },
   "outputs": [],
   "source": [
    "# Optimizador con learning rate programado\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00015,  # LR inicial m√°s alto\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "LlTJ647nPJZp",
    "outputId": "4f0e037c-b6cf-43a0-9650-d0311ad0450e"
   },
   "outputs": [],
   "source": [
    "# Callbacks mejorados\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=4,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.weights.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        min_delta=0.005\n",
    "    )\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uQefOZPT-8-",
    "outputId": "ccc5f87c-719d-4027-8b42-aca2dca69f49"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8px0LwqwohF"
   },
   "outputs": [],
   "source": [
    "# Paso 1: Construir el modelo\n",
    "model.build(input_shape=(None, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUl8jeULng41",
    "outputId": "d676da71-daab-4a44-ab9c-f2c8ea735275"
   },
   "outputs": [],
   "source": [
    "# Cargar modelo (de requerirlo)\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bX2sGj5uhnR",
    "outputId": "a0c2b54c-b6ed-4097-9e35-f03a841bfc38"
   },
   "outputs": [],
   "source": [
    "# Predecir\n",
    "y_pred_output = model.predict(X_test)\n",
    "y_pred_probs = y_pred_output.flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or8HagQswxUO",
    "outputId": "aea0992f-e832-423e-cd44-ef3943b2132d"
   },
   "outputs": [],
   "source": [
    "# M√©tricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\" M√©tricas\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTtwuQkNxNYZ",
    "outputId": "1a324d77-73c5-4959-9eaa-d85bae6332f4"
   },
   "outputs": [],
   "source": [
    "# Reporte de clasificaci√≥n\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Q62rAsWwtzQz",
    "outputId": "77d24e2a-dc7c-4a9f-8978-c60ce458ef27"
   },
   "outputs": [],
   "source": [
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Precisi√≥n\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy de Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy de Validaci√≥n')\n",
    "plt.title('Accuracy del Modelo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# P√©rdida\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "-8loMBpEv8qk",
    "outputId": "961d8db2-e694-4a7e-9274-339645aa8cdb"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 3)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.title('Matriz de Confusi√≥n')\n",
    "plt.ylabel('Realidad')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "maKA4C0CMKZC",
    "outputId": "9c43aa96-0a30-4e93-ec56-e12eb3c1d7e4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Modelo\": [\"Final (v3)\", \"Versi√≥n 1\", \"Versi√≥n 2\"],\n",
    "    \"val_accuracy_peak\": [0.7805, 0.7779, 0.7790],\n",
    "    \"val_loss_min\": [0.5704, 0.5717, 0.5436],\n",
    "    \"precision_peak\": [0.7848, 0.7806, 0.7870],\n",
    "    \"recall_peak\": [0.7829, 0.7904, 0.7671]\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# val_accuracy\n",
    "axes[0, 0].bar(df[\"Modelo\"], df[\"val_accuracy_peak\"], color=\"skyblue\")\n",
    "axes[0, 0].set_title(\"Val Accuracy Pico\")\n",
    "axes[0, 0].set_ylim(0.75, 0.79)\n",
    "axes[0, 0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "#  val_loss\n",
    "axes[0, 1].bar(df[\"Modelo\"], df[\"val_loss_min\"], color=\"salmon\")\n",
    "axes[0, 1].set_title(\"Val Loss M√≠nimo\")\n",
    "axes[0, 1].invert_yaxis()  # Menor es mejor\n",
    "axes[0, 1].set_ylabel(\"Loss\")\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].bar(df[\"Modelo\"], df[\"precision_peak\"], color=\"mediumseagreen\")\n",
    "axes[1, 0].set_title(\"Precisi√≥n Pico\")\n",
    "axes[1, 0].set_ylabel(\"Precision\")\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].bar(df[\"Modelo\"], df[\"recall_peak\"], color=\"orange\")\n",
    "axes[1, 1].set_title(\"Recall Pico\")\n",
    "axes[1, 1].set_ylabel(\"Recall\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlabel(\"Modelo\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwW-zQbvJC5W"
   },
   "source": [
    "### Justificaci√≥n del Modelo Final Seleccionado\n",
    "\n",
    "Se probaron tres configuraciones diferentes del modelo LSTM. A continuaci√≥n, se presenta una comparaci√≥n de sus principales caracter√≠sticas y m√©tricas de rendimiento:\n",
    "\n",
    "- **Versi√≥n 1** mostr√≥ un buen balance entre precisi√≥n y recall, pero el entrenamiento se detuvo temprano debido a estancamiento en val_accuracy. Adem√°s, su embed_dim era menor (192), lo cual puede limitar la capacidad de representaci√≥n sem√°ntica del texto.\n",
    "\n",
    "- **Versi√≥n 2** tuvo el mejor val_loss (0.5436), pero su val_accuracy fue levemente inferior y mostr√≥ cierta sobrecarga computacional (hasta 50 √©pocas). Su recall tambi√©n baj√≥ con respecto a la Versi√≥n 1, lo cual podr√≠a perjudicar la detecci√≥n de casos positivos.\n",
    "\n",
    "- **Versi√≥n final (v3)** logra un excelente balance:  \n",
    "   - Tiene **mejor precisi√≥n-recall equilibrado** (ambos ~0.78).\n",
    "   - La val_accuracy fue la **m√°s alta** (0.7805).\n",
    "   - Uso razonable de recursos (solo 30 √©pocas).\n",
    "   - Su tama√±o de embedding y n√∫mero de unidades LSTM es robusto pero no excesivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i84R0n16cudS"
   },
   "source": [
    "### Justificaci√≥n del Modelo Final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_Yn8aNDcwK7"
   },
   "source": [
    "El modelo seleccionado fue la **versi√≥n 3**, con una configuraci√≥n optimizada de hiperpar√°metros. Las decisiones se justifican de la siguiente manera:\n",
    "\n",
    "- **√âpocas (30) + EarlyStopping:** El entrenamiento se detuvo autom√°ticamente en la √©poca 29, cuando la mejora en validaci√≥n se estabiliz√≥. Las curvas de p√©rdida muestran convergencia clara sin overfitting. Esto indica una elecci√≥n adecuada de `epochs` y `patience`.\n",
    "\n",
    "- **Tasa de aprendizaje inicial: 1.5e-4** ‚Üí Se utiliz√≥ con `ReduceLROnPlateau`, lo cual permiti√≥ un **ajuste din√°mico** de la LR. Esto ayud√≥ a mantener mejoras en precisi√≥n y recall incluso en etapas tard√≠as del entrenamiento, estabilizando las m√©tricas.\n",
    "\n",
    "- **Batch size: 256** ‚Üí Este tama√±o balance√≥ eficiencia computacional y estabilidad del gradiente. En pruebas con batch sizes m√°s bajos (128), se observ√≥ mayor oscilaci√≥n en la curva de p√©rdida y menor precisi√≥n.\n",
    "\n",
    "En comparaci√≥n con versiones anteriores, esta configuraci√≥n alcanz√≥:\n",
    "- **Mayor accuracy de validaci√≥n (78.05%)**\n",
    "- **Mejor precisi√≥n y F1-score**\n",
    "- **Menor p√©rdida en validaci√≥n**\n",
    "\n",
    "#### Posibles mejoras:\n",
    "- Ajustar la LR inicial a 1e-4 podr√≠a permitir convergencia m√°s estable a√∫n.\n",
    "- Probar capas adicionales (p.ej., GRU + LSTM h√≠brido) podr√≠a mejorar el F1 en casos ambiguos.\n",
    "\n",
    "Estas decisiones fueron fundamentadas en pruebas emp√≠ricas y evidencia gr√°fica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUGIPtH2WJ-L"
   },
   "source": [
    "### An√°lisis de Hiperpar√°metros y su Impacto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGEZZYt6WMT7"
   },
   "source": [
    "| Hiperpar√°metro | Variaci√≥n entre versiones | Impacto observado |\n",
    "|----------------|---------------------------|--------------------|\n",
    "| `embed_dim`    | 192 -> 256                 | Mejor representaci√≥n sem√°ntica; el modelo final tuvo mayor precision y recall. |\n",
    "| `lstm_units`   | 192 -> 256 (v2)            | Aument√≥ capacidad, pero increment√≥ el tiempo de entrenamiento sin gran mejora en accuracy. |\n",
    "| `dropout_rate` | 0.4 -> 0.3 / 0.35          | Tasas moderadas mejoraron la generalizaci√≥n; tasas altas redujeron recall. |\n",
    "| `learning_rate`| 1e-4 / 1.5e-4 / 3e-5       | 1.5e-4 ofreci√≥ convergencia estable y buen rendimiento sin estancarse. |\n",
    "| `epochs`       | 30 -> 50                   | A partir de √©poca 20 no hubo grandes mejoras; el modelo final us√≥ early stopping. |\n",
    "| `batch_size`   | 256 (constante)           | Balance entre velocidad de entrenamiento y estabilidad del gradiente. |\n",
    "\n",
    "Las variaciones anteriores permitieron identificar que un embedding y LSTM intermedios (256, 192) combinados con una tasa de aprendizaje moderada (1.5e-4) ofrecen el mejor rendimiento sin sobreentrenar ni sobrecargar el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngUzYbEOcecD"
   },
   "source": [
    "### An√°lisis del desempe√±o del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6JzA9TNchN8"
   },
   "source": [
    "El modelo final logr√≥ una **accuracy del 77.0%** y un **F1-score de 0.7697**, valores consistentes con una buena capacidad de generalizaci√≥n en datos no vistos. La precisi√≥n (0.7698) y el recall (0.7695) est√°n balanceados, lo que indica que el modelo no favorece excesivamente ninguna clase.\n",
    "\n",
    "Estos resultados est√°n directamente relacionados con los **ajustes de hiperpar√°metros**, entre ellos:\n",
    "\n",
    "- **Dropout del 35%** y regularizaci√≥n L1/L2 ayudaron a reducir el overfitting, estabilizando las curvas de p√©rdida y mejorando la precisi√≥n de validaci√≥n tras la 10.¬™ √©poca.\n",
    "- El uso de **Bidirectional LSTM** permiti√≥ capturar contextos antes y despu√©s de cada palabra, mejorando recall y precisi√≥n frente a versiones unidireccionales.\n",
    "- La **capa de atenci√≥n** ayud√≥ a enfocar el modelo en tokens relevantes para el sentimiento, lo que se refleja en un mejor F1-score en comparaci√≥n con versiones sin atenci√≥n (~+1.5 pp).\n",
    "- El **batch size de 256** permiti√≥ convergencia m√°s estable en pocas √©pocas, sin saltos err√°ticos.\n",
    "\n",
    "En conclusi√≥n, las m√©tricas obtenidas est√°n directamente influenciadas por decisiones espec√≠ficas del modelo y evidencian una mejora sustancial respecto a versiones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnDt_h2Jr-qz"
   },
   "source": [
    "## Modelo RNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "wJo_rAw5sCMK",
    "outputId": "c0c83286-ed3c-4618-e7ae-225f77352a0c"
   },
   "outputs": [],
   "source": [
    "# Modelo RNN simple\n",
    "model_rnn_simple = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "        input_length=maxlen\n",
    "    ),\n",
    "    tf.keras.layers.SpatialDropout1D(dropout_rate),\n",
    "\n",
    "    # Capa RNN simple\n",
    "    tf.keras.layers.SimpleRNN(\n",
    "        lstm_units, # Reutilizamos el tama√±o de unidades para comparaci√≥n justa\n",
    "        dropout=dropout_rate,\n",
    "        recurrent_dropout=dropout_rate * 0.7,\n",
    "        return_sequences=False # Para una clasificaci√≥n simple final\n",
    "    ),\n",
    "\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(\n",
    "        dense_units,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn_simple.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', # Optimizador simple para empezar\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_rnn_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzOHhz8kuQEJ"
   },
   "source": [
    "\n",
    "Entrenamiento (usando menos epochs y batch size m√°s peque√±o para RNN simple)\n",
    "Se usan menos epochs y batch size m√°s peque√±o porque RNN simple suele ser m√°s r√°pido de entrenar\n",
    "pero puede tener problemas con secuencias largas y gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_UU8q6dxsH8P",
    "outputId": "ba3c869c-67d7-4168-aa21-1890df4ec53e"
   },
   "outputs": [],
   "source": [
    "history_rnn_simple = model_rnn_simple.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15, # Menos epochs para RNN simple\n",
    "    batch_size=128, # Batch size m√°s peque√±o\n",
    "    validation_split=0.2,\n",
    "    # No usamos callbacks avanzados ni class_weights para mantenerlo \"simple\"\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluaci√≥n\n",
    "loss_rnn_simple, accuracy_rnn_simple, precision_rnn_simple, recall_rnn_simple = model_rnn_simple.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\" M√©tricas RNN Simple\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Accuracy:  {accuracy_rnn_simple:.4f}\")\n",
    "print(f\"Precision: {precision_rnn_simple:.4f}\")\n",
    "print(f\"Recall:    {recall_rnn_simple:.4f}\")\n",
    "# Calculate F1 for RNN simple\n",
    "f1_rnn_simple = 2 * (precision_rnn_simple * recall_rnn_simple) / (precision_rnn_simple + recall_rnn_simple + 1e-7) # Add epsilon for stability\n",
    "print(f\"F1-score:  {f1_rnn_simple:.4f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Predecir para classification report and confusion matrix\n",
    "y_pred_rnn_simple_probs = model_rnn_simple.predict(X_test).flatten()\n",
    "y_pred_rnn_simple = (y_pred_rnn_simple_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Reporte de clasificaci√≥n RNN Simple\n",
    "print(\"\\nClassification Report (RNN Simple):\")\n",
    "print(classification_report(y_test, y_pred_rnn_simple, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Visualizaci√≥n para RNN Simple\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# P√©rdida RNN Simple\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_rnn_simple.history['loss'], label='Train Loss (RNN Simple)')\n",
    "plt.plot(history_rnn_simple.history['val_loss'], label='Validation Loss (RNN Simple)')\n",
    "plt.title('Model Loss (RNN Simple)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Matriz de confusi√≥n RNN Simple\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_rnn_simple = confusion_matrix(y_test, y_pred_rnn_simple)\n",
    "sns.heatmap(cm_rnn_simple, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negativo', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.title('Confusion Matrix (RNN Simple)')\n",
    "plt.ylabel('Realidad')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo (de requerirlo)\n",
    "from keras.models import load_model\n",
    "\n",
    "model_rnn_simple = load_model(\"rnn_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oveb1NoSu_nI"
   },
   "source": [
    "## Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "6aK_Q6hGxhIl",
    "outputId": "ae3aa50d-41cc-41cf-b3f6-2d47a8ff401a"
   },
   "outputs": [],
   "source": [
    "# Gr√°fico de m√©tricas finales (Barras)\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "lstm_scores = [accuracy_best, precision_best, recall_best, f1_best]\n",
    "rnn_scores = [accuracy_rnn_simple, precision_rnn_simple, recall_rnn_simple, f1_rnn_simple]\n",
    "\n",
    "x = np.arange(len(metrics_names))  # posiciones en el eje x\n",
    "width = 0.35  # ancho de las barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, lstm_scores, width, label='Best Model (LSTM)', color='steelblue')\n",
    "rects2 = ax.bar(x + width/2, rnn_scores, width, label='RNN Simple', color='orange')\n",
    "\n",
    "# Etiquetas y formato\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparaci√≥n de M√©tricas Finales por Modelo')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_names)\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar valores en las barras\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.4f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # Desplazamiento vertical\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\"*65)\n",
    "print(\" \"*15 + \"COMPARACI√ìN DE M√âTRICAS DE MODELOS \")\n",
    "print(\"-\"*65)\n",
    "print(comparison_df)\n",
    "print(\"-\"*65 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoSlPoiNIiTB"
   },
   "source": [
    "### An√°lisis Comparativo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLyQ0Wo6QF8N"
   },
   "source": [
    "Con el resulado de ambos modelos podemos comparar sus metricas de clasificaci√≥n y as√≠ poder diferenciarlos para detectar cu√°l tiene un mejor rendimiento para realizar predicci√≥n de sentimientos.\n",
    "\n",
    "\n",
    "| M√©trica   | LSTM   | RNN Simple | Diferencia |\n",
    "| --------- | ------ | ---------- | ---------- |\n",
    "| Accuracy  | 0.7704 | 0.7292     | +0.0412    |\n",
    "| Precision | 0.7698 | 0.7274     | +0.0424    |\n",
    "| Recall    | 0.7695 | 0.7306     | +0.0389    |\n",
    "| F1-score  | 0.7697 | 0.7290     | +0.0407    |\n",
    "\n",
    "**Ventajas del modelo LSTM**\n",
    "\n",
    "Mayor rendimiento en todas las m√©tricas clave:\n",
    "\n",
    "* Accuracy: El LSTM supera al RNN simple por un margen de `+4.12%`, lo que indica que clasifica correctamente m√°s muestras en general.\n",
    "\n",
    "* Precision y Recall: El LSTM es m√°s preciso (menos falsos positivos) y tiene mejor sensibilidad (menos falsos negativos), lo que significa que detecta mejor las clases positivas sin sobreclasificarlas.\n",
    "\n",
    "* F1-score: La puntuaci√≥n F1 es `+4.07%` superior en LSTM, lo que sugiere un balance m√°s efectivo entre ambas.\n",
    "\n",
    "Mayor capacidad de aprendizaje secuencial:\n",
    "\n",
    "El modelo LSTM incorpora puertas (como input, forget y output gates) que le permiten capturar dependencias a largo plazo en los datos, algo que el RNN simple no logra con la misma eficacia.\n",
    "\n",
    "Mayor estabilidad y generalizaci√≥n:\n",
    "\n",
    "El modelo LSTM, al ser m√°s robusto frente al desvanecimiento del gradiente, aprende de manera m√°s estable durante el entrenamiento y generaliza mejor al conjunto de prueba.\n",
    "\n",
    "**Limitaciones del modelo RNN Simple**\n",
    "\n",
    "Aunque el RNN simple es m√°s liviano computacionalmente, su rendimiento es notablemente inferior en todos los aspectos y se ve claramente comparando ambos modelos en el gr√°fico. √âste modelo es m√°s propenso al desvanecimiento del gradiente, lo que limita su capacidad para aprender dependencias temporales largas.\n",
    "\n",
    "**Conclusi√≥n**\n",
    "\n",
    "El modelo final elegido es una arquitectura LSTM bidireccional con atenci√≥n, que logra un equilibrio ideal entre rendimiento, estabilidad y capacidad de modelar lenguaje secuencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh-ljJl7QIRh"
   },
   "source": [
    "## Justificaci√≥n del Modelo Final: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cHAp3UnSRLz"
   },
   "source": [
    "Se eligi√≥ el modelo LSTM (Long Short-Term Memory) como modelo final debido a su mejor rendimiento cuantitativo y cualitativo en comparaci√≥n con la arquitectura RNN simple, y por su capacidad superior para aprender patrones secuenciales en los datos.\n",
    "\n",
    "En nuestro caso:\n",
    "\n",
    "- Trabajamos con tweets donde la clave del sentimiento puede aparecer en cualquier parte de la frase (dependencias de largo alcance).  \n",
    "- En la comparaci√≥n emp√≠rica, el modelo LSTM super√≥ sistem√°ticamente a la RNN simple en accuracy, precision, recall y F1-score (‚âà +4 pp en cada m√©trica).  \n",
    "- Si bien la RNN simple es m√°s ligera (menos par√°metros y entrenamiento algo m√°s r√°pido), su menor estabilidad y peor desempe√±o la hacen menos adecuada para esta tarea de an√°lisis de sentimientos.\n",
    "\n",
    "Por estas razones, se eligi√≥ **LSTM bidireccional con atenci√≥n**, que combina la robustez de las LSTM con la capacidad de enfocarse en las palabras m√°s relevantes mediante la capa de atenci√≥n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djl__QEQSW9D"
   },
   "source": [
    "## Prediccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoK57e0wSWcG"
   },
   "outputs": [],
   "source": [
    "def predecir_sentimiento(texto):\n",
    "    if 'model' not in globals() or 'tokenizer' not in globals():\n",
    "        print(\"Error: El modelo o el tokenizer no est√°n definidos. Aseg√∫rate de haber entrenado el modelo previamente.\")\n",
    "        return None\n",
    "\n",
    "    # Limpiar y tokenizar el texto de entrada\n",
    "    texto_limpio = limpiar_texto_mejorado(texto)\n",
    "    secuencia = tokenizer.texts_to_sequences([texto_limpio])\n",
    "    secuencia_padding = tf.keras.preprocessing.sequence.pad_sequences(secuencia, maxlen=maxlen)\n",
    "\n",
    "    # Realizar la predicci√≥n\n",
    "    prediccion_prob = model.predict(secuencia_padding)[0][0]\n",
    "\n",
    "    # Interpretar la predicci√≥n\n",
    "    if prediccion_prob > 0.5:\n",
    "        return 'Positivo'\n",
    "    else:\n",
    "        return 'Negativo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeQ9rbqRaqI3",
    "outputId": "a0030079-6ce3-4c22-972c-550cd49457b9"
   },
   "outputs": [],
   "source": [
    "frases_positivas = [\n",
    "    \"I absolutely loved this!\",                      # Muy obvio\n",
    "    \"This is fantastic and made my day.\",            # Claro y entusiasta\n",
    "    \"I'm really happy with how it turned out.\",      # Positivo expl√≠cito\n",
    "    \"Not bad at all, pretty good actually.\",         # Sutil, con negaci√≥n\n",
    "    \"It was better than I expected.\"                 # Positivo impl√≠cito\n",
    "]\n",
    "\n",
    "frases_negativas = [\n",
    "    \"This is the worst thing ever.\",                 # Muy obvio\n",
    "    \"I completely hated it.\",                        # Claro y negativo\n",
    "    \"I'm really disappointed with this.\",            # Negativo expl√≠cito\n",
    "    \"Not what I hoped for, honestly.\",               # Sutil, con decepci√≥n\n",
    "    \"It wasn't great.\"                               # Negativo impl√≠cito\n",
    "]\n",
    "\n",
    "print(\"üü¢ Frases Positivas:\")\n",
    "for frase in frases_positivas:\n",
    "    sentimiento = predecir_sentimiento(frase)\n",
    "    print(f\"Texto: '{frase}' -> Sentimiento: {sentimiento}\")\n",
    "\n",
    "print(\"\\nüî¥ Frases Negativas:\")\n",
    "for frase in frases_negativas:\n",
    "    sentimiento = predecir_sentimiento(frase)\n",
    "    print(f\"Texto: '{frase}' -> Sentimiento: {sentimiento}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ4OuYifa5D3"
   },
   "source": [
    "### Validaci√≥n Manual de Casos Reales\n",
    "\n",
    "Se prob√≥ el modelo con frases en ingl√©s que representan distintos niveles de carga emocional y estructuras ling√º√≠sticas:\n",
    "\n",
    "| Texto                                     | Esperado | Predicho | Correcto |\n",
    "|------------------------------------------|----------|----------|----------|\n",
    "| I absolutely loved this!                 | Positivo | Positivo | ‚úÖ       |\n",
    "| Not bad at all, pretty good actually.    | Positivo | Negativo | ‚ùå       |\n",
    "| I completely hated it.                   | Negativo | Positivo | ‚ùå       |\n",
    "| It wasn't great.                         | Negativo | Positivo | ‚ùå       |\n",
    "\n",
    "Aunque el modelo muestra buen rendimiento en ejemplos directos, fall√≥ en frases con negaciones y expresiones suaves. Esto evidencia una limitaci√≥n de los modelos LSTM puros para interpretar matices y estructuras complejas del lenguaje natural.\n",
    "\n",
    "Estos resultados muestran que el modelo funciona bien en lo general, pero no:\n",
    "\n",
    "* Comprende bien negaciones compuestas (\"not bad\", \"wasn't great\").\n",
    "* Interpreta correctamente palabras negativas cuando est√°n fuera del patr√≥n de entrenamiento.\n",
    "* Modela bien el contexto y la inversi√≥n sem√°ntica (ej. iron√≠a o sarcasmo leve).\n",
    "\n",
    "Este tipo de errores son t√≠picos en LSTM puros sin embeddings sem√°nticos preentrenados (como los de BERT o GPT), porque dependen mucho de patrones superficiales y del vocabulario aprendido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGXGJhWeaXvp"
   },
   "source": [
    "### Consideraciones sobre el Idioma del Dataset\n",
    "\n",
    "El modelo fue entrenado exclusivamente con el dataset **Sentiment140**, el cual est√° compuesto por tweets en **ingl√©s**. Por esta raz√≥n, su vocabulario, embeddings y patrones de sentimiento fueron aprendidos √∫nicamente a partir de ese idioma.\n",
    "\n",
    "Durante pruebas preliminares, se observ√≥ que frases en espa√±ol eran clasificadas incorrectamente. Al cambiar los ejemplos de prueba al ingl√©s, el modelo respondi√≥ correctamente, clasificando de forma precisa tanto frases positivas como negativas.\n",
    "\n",
    "Este modelo no est√° dise√±ado para tareas de an√°lisis de sentimientos en espa√±ol. Para ello, se requerir√≠a un corpus en espa√±ol o un modelo multiling√ºe (como `BERT multilingual`).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4P1EzEYexblM",
    "rnDt_h2Jr-qz",
    "oveb1NoSu_nI"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
